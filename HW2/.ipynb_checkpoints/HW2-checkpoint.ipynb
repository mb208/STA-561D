{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3\n",
    "- Authors: Marc Brooks, Jack McCarthy, Michael Sarkis\n",
    "- NetID: mgb45, ___ , ms939"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) (Hard-thresholding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(a)\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}Z\\textbf{1}_{\\left| Z \\right| \\le \\gamma}\n",
    "&= \\int_{-\\infty}^{\\infty} \\frac{z}{\\tau \\sqrt{2 \\pi}} e^{-\\frac{1}{2}\\left( \\frac{z-\\omega}{\\tau} \\right)^2}\\textbf{1}_{\\left| Z \\right| \\le \\gamma} dz \\\\\n",
    "&= \\frac{1}{\\sqrt{2 \\pi}}\\int_{-\\gamma}^{\\gamma} \\frac{z}{\\tau} e^{-\\frac{1}{2}\\left( \\frac{z-\\omega}{\\tau} \\right)^2} dz\n",
    "\\end{aligned}\n",
    "\n",
    "Let $u = \\frac{z-\\omega}{\\tau}$, so $z = u \\tau + \\omega$ and $du = \\frac{1}{\\tau}dz$. Substituting these in we get the following:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{1}{\\sqrt{2 \\pi}}\\int_{-\\gamma}^{\\gamma} \\frac{z}{\\tau} e^{-\\frac{1}{2}\\left( \\frac{z-\\omega}{\\tau} \\right)^2} dz\n",
    "&= \\frac{1}{\\sqrt{2 \\pi}} \\left[ \\int (u \\tau + \\omega)e^{-\\frac{1}{2}u^2}du \\right]_{-\\frac{\\gamma + \\omega}{\\tau}}^{\\frac{\\gamma - \\omega}{\\tau}} \\\\\n",
    "&= \\frac{1}{\\sqrt{2 \\pi}} \\left[ \\tau \\int ue^{-\\frac{1}{2}u^2}du + \\omega \\int e^{-\\frac{1}{2}u^2}du \\right]_{-\\frac{\\gamma + \\omega}{\\tau}}^{\\frac{\\gamma - \\omega}{\\tau}} \\\\\n",
    "&= \\frac{1}{\\sqrt{2 \\pi}} \\left[ -\\tau e^{-\\frac{1}{2} u^2} + \\frac{\\omega \\sqrt{\\pi}}{\\sqrt{2}} \\text{erf} \\left( \\frac{u}{\\sqrt{2}} \\right) \\right]_{-\\frac{\\gamma + \\omega}{\\tau}}^{\\frac{\\gamma - \\omega}{\\tau}} \\\\\n",
    "&= \\left[ -\\frac{\\tau}{\\sqrt{2 \\pi}} e^{-\\frac{1}{2}u^2} + \\frac{\\omega}{2} \\text{erf} \\left( \\frac{u}{\\sqrt{2}} \\right) \\right]_{-\\frac{\\gamma + \\omega}{\\tau}}^{\\frac{\\gamma - \\omega}{\\tau}}\n",
    "\\end{aligned}\n",
    "\n",
    "Which evaluated gives:\n",
    "$$\\mathbb{E}Z\\textbf{1}_{\\left| Z \\right| \\le \\gamma} = \\frac{\\omega}{2} \\left[ \\text{erf} \\left( \\frac{\\gamma-\\omega}{\\tau \\sqrt{2}} \\right) - \\text{erf} \\left( \\frac{-(\\gamma+\\omega)}{\\tau \\sqrt{2}} \\right) \\right] - \\frac{\\tau}{\\sqrt{2 \\pi}} \\left[ \\exp\\left\\{-\\frac{1}{2}\\left( \\frac{\\gamma-\\omega}{\\tau} \\right)^2\\right\\} - \\exp\\left\\{-\\frac{1}{2}\\left( \\frac{-(\\gamma+\\omega)}{\\tau} \\right)^2\\right\\} \\right]$$\n",
    "\n",
    "(b)\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}\\left( X - \\hat{\\mu}_n^H \\right)^2 \n",
    "           &= \\mathbb{E}\\left[ (X - \\mu) + (\\mu - \\hat{\\mu}_n^H) \\right]^2 \\\\\n",
    "           &= \\mathbb{E}\\left[ (X - \\mu)^2 + 2(X - \\mu)(\\mu + \\hat{\\mu}_n^H) + (\\mu - \\hat{\\mu}_n^H)^2 \\right] \\\\\n",
    "           &= \\mathbb{E}(X - \\mu)^2 - 2\\mathbb{E}(X - \\mu)(\\mu + \\hat{\\mu}_n^H) + \\mathbb{E}(\\mu - \\hat{\\mu}_n^H)^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}(\\mu - \\hat{\\mu}_n^H)^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}\\left[ (\\mu - \\mathbb{E}\\hat{\\mu}_n^H) + (\\mathbb{E}\\hat{\\mu}_n^H - \\hat{\\mu}_n^H) \\right]^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}(\\mu - \\mathbb{E}\\hat{\\mu}_n^H)^2 + \\mathbb{E}(\\mathbb{E}\\hat{\\mu}_n^H - \\hat{\\mu}_n^H)^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}(\\mu - \\mathbb{E}\\hat{\\mu}_n^H)^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}\\left(\\mu^2 - 2\\mu\\mathbb{E}\\hat{\\mu}_n^H + \\left(\\mathbb{E}\\hat{\\mu}_n^H\\right)^2 \\right) \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}\\mu^2 - 2\\mu\\mathbb{E}\\hat{\\mu}_n^H + \\left(\\mathbb{E}\\hat{\\mu}_n^H\\right)^2 \\\\\n",
    "           &= \\sigma^2 + \\mu^2 - 2\\mu\\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\ge \\alpha} \n",
    "           + \\left(\\mathbb{E}\\bar{X}_n\\textbf{1}_{\\left| \\bar{X}_n \\right| \\ge \\alpha} \\right)^2 \\\\\n",
    "           &= \\sigma^2 + \\mu^2 \n",
    "           - 2\\mu\\left[\\mathbb{E}\\bar{X}_n - \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right] \n",
    "           + \\left[\\mathbb{E}\\bar{X}_n - \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right]^2 \\\\\n",
    "           &= \\sigma^2 + \\mu^2 - 2\\mu^2 + 2\\mu \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha}\n",
    "           + \\left( \\mathbb{E}\\bar{X}_n \\right)^2 - 2\\mathbb{E}\\bar{X}_n \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \n",
    "           + \\left( \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right)^2 \\\\\n",
    "           &= \\sigma^2 - \\mu^2 + 2\\mu \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} + \\mu^2 - 2\\mu \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} + \\left( \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right)^2 \\\\\n",
    "           &= \\sigma^2 + \\left( \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right)^2\n",
    "\\end{aligned}\n",
    "\n",
    "We can plug the closed form from (a) in for $\\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha}$ for a final closed form of $\\mathbb{E}\\left( X - \\hat{\\mu}_n^H \\right)^2$ (not done to save space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (Great British Bake-off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoLarsIC, LassoLarsCV, RidgeCV, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, since $\\epsilon$ and $\\textbf{X}$ are independent we can see that: \n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Var}(Y) &= \\text{Var}(\\textbf{X}^{T}\\beta^{*} + \\epsilon) \\\\\n",
    "&= \\text{Var}(\\textbf{X}^{T}\\beta^{*}) + \\text{Var}(\\epsilon) \\\\\n",
    "&= \\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2 \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Furthmore, we recognize $P(Y - \\textbf{X}^{T}\\beta^{*})^{2} = P\\epsilon^{2}$ as the expected squared residuals.\n",
    "Since $P\\epsilon = 0$ then $P\\epsilon^2 = \\sigma^2$ and $P(Y - \\textbf{X}^{T}\\beta^{*})^{2} = \\sigma^2$.\n",
    "\n",
    "\n",
    "Thus,\n",
    "$$\n",
    "\\begin{align}\n",
    "R^{2} &= 1 - \\frac{P(Y - \\textbf{X}^{T}\\beta^{*})^{2}}{\\text{Var}(Y)} \\\\\n",
    "&= 1 - \\frac{\\sigma^2}{\\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting $R^2 = .8$ we can solve for $\\sigma^2$ as follows.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    ".8 &= 1 - \\frac{\\sigma^2}{\\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2} \\\\\n",
    ".2 &= \\frac{\\sigma^2}{\\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2} \\\\\n",
    "\\sigma^2 &= .2(\\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2)  \\\\\n",
    ".8\\sigma^2 &= .2(\\beta^{*T}\\Sigma(\\rho)\\beta^{*})  \\\\\n",
    "\\sigma^2 &= .25(\\beta^{*T}\\Sigma(\\rho)\\beta^{*}) \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = [10, 25, 50]\n",
    "rho = [0, .25, .5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating data sets with sparse signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bc5f1a0adac8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X @ np.diagflat(np.abs(lm_spr.coef_))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['lasso']*3 + ['adpt lasso']*3 + ['ridge']*3 + ['adpt ridge']*3\n",
    "tunings = ['AIC', 'BIC', 'LOO-CV']*4\n",
    "labs = [labels[i] + ' ' + tunings[i] for i in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-75-a25a3e8cb16f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-75-a25a3e8cb16f>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    None                 labs,\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "emse_table = pd.DataFrame(itertools.product(['sparse', 'dense'], \n",
    "              None                 labs,\n",
    "                               [10,25,50],\n",
    "                               [0,.25,.5]), \n",
    "             columns=['signal','Method-Tuning', 'p', 'rho'])\n",
    "\n",
    "emse_table['mse'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emse_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-6e9ef517607d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0memse_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'emse_table' is not defined"
     ]
    }
   ],
   "source": [
    "emse_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9418ae671d63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "U, D, V = np.linalg.svd(X, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(D**2/(D**2 + .02)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bic(y_hat, y, D, lamb):\n",
    "    df_l = np.sum(D**2/(D**2 + lamb))\n",
    "    rss = np.sum((y - y_hat)**2)\n",
    "    bic = np.log(rss) + df_l*np.log(len(y))/len(y)\n",
    "    return bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_aic(y_hat, y, D, lamb):\n",
    "    df_l = np.sum(D**2/(D**2 + lamb))\n",
    "    rss = np.sum((y - y_hat)**2)\n",
    "    aic = np.log(rss) + df_l*2/len(y)\n",
    "    return aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_ic(lambs, X, Y, X_star, Y_star, ic='aic'):\n",
    "    U, D, V = np.linalg.svd(X, full_matrices=False)\n",
    "    y_pred = lambda l: (U @ np.diag(D**2/(D**2 + l)) @ U.T) @ Y   \n",
    "    if ic=='bic':\n",
    "        bic_vals = np.array([calc_bic(y_hat = y_pred(l), y=Y, D=D, lamb=l) for l in lambs])\n",
    "        min_i = np.argmin(bic_vals)\n",
    "    else:\n",
    "        aic_vals = np.array([calc_aic(y_hat = y_pred(l), y=Y, D=D, lamb=l) for l in lambs])\n",
    "        min_i = np.argmin(aic_vals)\n",
    "    mse = mean_squared_error(Y, y_pred(lambs[min_i]))\n",
    "    beta_hat = np.linalg.inv(X.T @ X + lambs[min_i]*np.eye(p)) @ X.T @ Y\n",
    "    omse = mean_squared_error(Y_star, X_star @ beta_hat)\n",
    "    return mse, lambs[min_i], omse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "? np.linalg.svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:26<?, ?it/s]1.33s/it]\n",
      " 43%|████▎     | 426/1000 [09:59<14:14,  1.49s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n = 100\n",
    "count = 0\n",
    "test_size = 1000\n",
    "for p,rho in itertools.product([10, 25, 50],[0, 0.25, 0.5]):\n",
    "    print(p, rho)\n",
    "    \n",
    "    # Generate data\n",
    "    beta_spr = np.fromfunction(lambda j, _: (2 / np.sqrt(n)) * (j + 1 <= np.sqrt(p)), (p, 1))\n",
    "    beta_dns = np.fromfunction(lambda j, _: (5 / (j + 1) * np.sqrt(n)), (p, 1))\n",
    "\n",
    "    Sigma_p = np.fromfunction(lambda i, j: rho**(np.abs(i - j)), (p, p))\n",
    "    sigma2_spr = 0.25 * (beta_spr.T @ Sigma_p @ beta_spr)\n",
    "    sigma2_dns = 0.25 * (beta_dns.T @ Sigma_p @ beta_dns)\n",
    "    \n",
    "    \n",
    "    #Generate Test sets for given Rho and p\n",
    "    test_epsilon_spr = np.random.normal(loc=0, scale=np.sqrt(sigma2_spr))\n",
    "    test_epsilon_dns = np.random.normal(loc=0, scale=np.sqrt(sigma2_dns))\n",
    "    \n",
    "    test_X = np.random.multivariate_normal(mean=np.zeros(p), cov=Sigma_p, size=test_size)\n",
    "\n",
    "    test_Y_spr =  test_X @ beta_spr + test_epsilon_spr\n",
    "    test_Y_dns =  test_X @ beta_dns + test_epsilon_dns\n",
    "    \n",
    "    # Sparse Signal\n",
    "    lasso_aic_mse_spr = 0\n",
    "    lasso_bic_mse_spr = 0\n",
    "    lasso_loocv_mse_spr = 0\n",
    "    adp_lasso_aic_mse_spr = 0\n",
    "    adp_lasso_bic_mse_spr = 0\n",
    "    adp_lasso_loocv_mse_spr = 0\n",
    "    \n",
    "    ridge_aic_mse_spr = 0\n",
    "    ridge_bic_mse_spr = 0\n",
    "    ridge_loocv_mse_spr = 0\n",
    "    adp_ridge_aic_mse_spr = 0\n",
    "    adp_ridge_bic_mse_spr = 0\n",
    "    adp_ridge_loocv_mse_spr = 0\n",
    "    \n",
    "    # Dense Signal \n",
    "    lasso_aic_mse_dns = 0\n",
    "    lasso_bic_mse_dns = 0\n",
    "    lasso_loocv_mse_dns = 0\n",
    "    adp_lasso_aic_mse_dns = 0\n",
    "    adp_lasso_bic_mse_dns = 0\n",
    "    adp_lasso_loocv_mse_dns = 0\n",
    "    \n",
    "    ridge_aic_mse_dns = 0\n",
    "    ridge_bic_mse_dns = 0\n",
    "    ridge_loocv_mse_dns = 0\n",
    "    adp_ridge_aic_mse_dns = 0\n",
    "    adp_ridge_bic_mse_dns = 0\n",
    "    adp_ridge_loocv_mse_dns = 0\n",
    "    \n",
    "    # For LOO-CV\n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    prog = tqdm(total = 1000, position=0, leave=2)\n",
    "    \n",
    "    for _ in range(1000):\n",
    "        \n",
    "        #To divide out mse sums later\n",
    "        count += 1 \n",
    "        \n",
    "        # Create Dataset\n",
    "        epsilon_spr = np.random.normal(loc=0, scale=np.sqrt(sigma2_spr))\n",
    "        epsilon_dns = np.random.normal(loc=0, scale=np.sqrt(sigma2_dns))\n",
    "\n",
    "        X = np.random.multivariate_normal(mean=np.zeros(p), cov=Sigma_p, size=n)\n",
    "\n",
    "        Y_spr =  X @ beta_spr + epsilon_spr\n",
    "        Y_dns =  X @ beta_dns + epsilon_dns\n",
    "\n",
    "        # For adaptive regressions\n",
    "        lm_spr = LinearRegression().fit(X, Y_spr)\n",
    "        lm_dns = LinearRegression().fit(X, Y_dns)\n",
    "        \n",
    "        # Adpative Lasso\n",
    "        # Here we are compute X^T (D^-1)^T\n",
    "        adX_sprL = X @ np.diagflat(np.abs(lm_spr.coef_))\n",
    "        adX_dnsL = X @ np.diagflat(np.abs(lm_dns.coef_))\n",
    "        \n",
    "        # Adpative Ridge\n",
    "        adX_sprR = X @ np.diagflat((lm_spr.coef_**2)**(1/2))\n",
    "        adX_dnsR = X @ np.diagflat((lm_dns.coef_**2)**(1/2))\n",
    "    \n",
    "        # Calculate Lassos\n",
    "        \n",
    "        # AIC\n",
    "        \n",
    "        # Sparse\n",
    "        lasso_aic_spr = LassoLarsIC(criterion='aic')\n",
    "        lasso_aic_spr.fit(X, Y_spr)\n",
    "        lasso_aic_mse_spr += mean_squared_error(test_Y_spr, lasso_aic_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        lasso_aic_dns = LassoLarsIC(criterion='aic')\n",
    "        lasso_aic_dns.fit(X, Y_dns)\n",
    "        lasso_aic_mse_dns += mean_squared_error(test_Y_dns, lasso_aic_dns.predict(test_X))\n",
    "        \n",
    "        #BIC\n",
    "        \n",
    "        # Sparse\n",
    "        lasso_bic_spr = LassoLarsIC(criterion='bic')\n",
    "        lasso_bic_spr.fit(X, Y_spr)\n",
    "        lasso_bic_mse_spr += mean_squared_error(test_Y_spr, lasso_bic_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        lasso_bic_dns = LassoLarsIC(criterion='bic')\n",
    "        lasso_bic_dns.fit(X, Y_dns)\n",
    "        lasso_bic_mse_dns += mean_squared_error(test_Y_dns, lasso_bic_dns.predict(test_X))\n",
    "        \n",
    "        #LOO-CV\n",
    "        \n",
    "        # Sparse\n",
    "        lasso_loo_spr = LassoLarsCV(cv=loo)\n",
    "        lasso_loo_spr.fit(X, Y_spr)\n",
    "        lasso_loocv_mse_spr += mean_squared_error(test_Y_spr, lasso_loo_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        lasso_loo_dns = LassoLarsCV(cv=loo)\n",
    "        lasso_loo_dns.fit(X, Y_dns)\n",
    "        lasso_loocv_mse_spr += mean_squared_error(test_Y_dns, lasso_loo_dns.predict(test_X))\n",
    "\n",
    "        # Adaptive Lasso\n",
    "        \n",
    "        # AIC\n",
    "        \n",
    "        # Sparse\n",
    "        adp_lasso_aic_spr = LassoLarsIC(criterion='aic')\n",
    "        adp_lasso_aic_spr.fit(adX_sprL, Y_spr)\n",
    "        adp_lasso_aic_mse_spr += mean_squared_error(test_Y_spr, adp_lasso_aic_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        adp_lasso_aic_dns = LassoLarsIC(criterion='aic')\n",
    "        adp_lasso_aic_dns.fit(adX_dnsL, Y_dns)\n",
    "        adp_lasso_aic_mse_dns += mean_squared_error(test_Y_dns, adp_lasso_aic_dns.predict(test_X))\n",
    "        \n",
    "        # BIC\n",
    "        \n",
    "        # Sparse\n",
    "        adp_lasso_bic_spr = LassoLarsIC(criterion='bic')\n",
    "        adp_lasso_bic_spr.fit(adX_sprL, Y_spr)\n",
    "        adp_lasso_bic_mse_spr += mean_squared_error(test_Y_spr, adp_lasso_bic_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        adp_lasso_bic_dns = LassoLarsIC(criterion='bic')\n",
    "        adp_lasso_bic_dns.fit(adX_dnsL, Y_dns)\n",
    "        adp_lasso_bic_mse_dns += mean_squared_error(test_Y_dns, adp_lasso_bic_dns.predict(test_X))\n",
    "        \n",
    "        # LOO-CV\n",
    "        \n",
    "        # Sparse\n",
    "        #adp_lasso_loo_spr = LassoLarsCV(cv=loo)\n",
    "        #adp_lasso_loo_spr.fit(adX_sprL, Y_spr)\n",
    "        #adp_lasso_loocv_mse_spr += mean_squared_error(test_Y_spr, adp_lasso_loo_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        #adp_lasso_loo_dns = LassoLarsCV(cv=loo)\n",
    "        #adp_lasso_loo_dns.fit(adX_dnsL, Y_dns)\n",
    "        #adp_lasso_loocv_mse_dns += mean_squared_error(test_Y_dns, adp_lasso_loo_dns.predict(test_X))\n",
    "\n",
    "        # Calculate Ridge\n",
    "        # AIC\n",
    "        \n",
    "        lambda_rng = np.linspace(0,100,num = 200)\n",
    "        \n",
    "        #Sparse\n",
    "        _,__,mse = lambda_ic(lambda_rng, X, Y_spr, test_X, test_Y_spr, ic='aic')\n",
    "        ridge_aic_mse_spr += mse\n",
    "        \n",
    "        #Dense\n",
    "        _,__,mse = lambda_ic(lambda_rng, X, Y_dns, test_X, test_Y_dns, ic='aic')\n",
    "        ridge_aic_mse_dns += mse\n",
    "        \n",
    "        #BIC\n",
    "        #Sparse\n",
    "        _,__,mse = lambda_ic(lambda_rng, X, Y_spr, test_X, test_Y_spr, ic='bic')\n",
    "        ridge_bic_mse_spr += mse\n",
    "        \n",
    "        #Dense\n",
    "        _,__,mse = lambda_ic(lambda_rng, X, Y_dns, test_X, test_Y_dns, ic='bic')\n",
    "        ridge_bic_mse_dns += mse\n",
    "        #LOO-CV\n",
    "        \n",
    "        #Sparse\n",
    "        ridge_loo_spr = RidgeCV(cv = loo)\n",
    "        ridge_loo_spr.fit(X,Y_spr)\n",
    "        ridge_loocv_mse_spr += mean_squared_error(test_Y_spr, ridge_loo_spr.predict(test_X))\n",
    "        \n",
    "        #Dense\n",
    "        ridge_loo_dns = RidgeCV(cv = loo)\n",
    "        ridge_loo_dns.fit(X,Y_dns)\n",
    "        ridge_loocv_mse_dns += mean_squared_error(test_Y_dns, ridge_loo_dns.predict(test_X))\n",
    "\n",
    "        #Adaptive Ridge\n",
    "        # AIC\n",
    "        \n",
    "        #Sparse\n",
    "        _,__,mse = lambda_ic(lambda_rng,  adX_sprR, Y_spr, test_X, test_Y_spr, ic='aic')\n",
    "        adp_ridge_aic_mse_spr += mse\n",
    "        \n",
    "        #Dense\n",
    "        _,__,mse = lambda_ic(lambda_rng,  adX_dnsR, Y_dns, test_X, test_Y_dns, ic='aic')\n",
    "        adp_ridge_aic_mse_dns += mse\n",
    "        \n",
    "        #BIC\n",
    "        #Sparse\n",
    "        _,__,mse = lambda_ic(lambda_rng,  adX_sprR, Y_spr, test_X, test_Y_spr, ic='bic')\n",
    "        adp_ridge_bic_mse_spr += mse\n",
    "        \n",
    "        #Dense\n",
    "        _,__,mse = lambda_ic(lambda_rng,  adX_dnsR, Y_dns, test_X, test_Y_dns, ic='bic')\n",
    "        adp_ridge_bic_mse_dns += mse\n",
    "\n",
    "        # LOO-CV\n",
    "        \n",
    "        #Sparse\n",
    "        adp_ridge_loo_spr = RidgeCV(cv = loo)\n",
    "        adp_ridge_loo_spr.fit(adX_sprR,Y_spr)\n",
    "        adp_ridge_loocv_mse_spr += mean_squared_error(test_Y_spr, ridge_loo_spr.predict(test_X))\n",
    "        \n",
    "        #Dense\n",
    "        adp_ridge_loo_dns = RidgeCV(cv = loo)\n",
    "        adp_ridge_loo_dns.fit(adX_dnsR,Y_dns)\n",
    "        adp_ridge_loocv_mse_dns += mean_squared_error(test_Y_dns, ridge_loo_dns.predict(test_X))\n",
    "\n",
    "        \n",
    "        prog.update()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
