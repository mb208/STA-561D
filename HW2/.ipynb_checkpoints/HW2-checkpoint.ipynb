{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "internal-privilege",
   "metadata": {},
   "source": [
    "# HW 3\n",
    "- Author: Marc Brooks\n",
    "- NetID: mgb45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-brass",
   "metadata": {},
   "source": [
    "## 1.) (Hard-thresholding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-drawing",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(a)\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}Z\\textbf{1}_{\\left| Z \\right| \\le \\gamma}\n",
    "&= \\int_{-\\infty}^{\\infty} \\frac{z}{\\tau \\sqrt{2 \\pi}} e^{-\\frac{1}{2}\\left( \\frac{z-\\omega}{\\tau} \\right)^2}\\textbf{1}_{\\left| Z \\right| \\le \\gamma} dz \\\\\n",
    "&= \\frac{1}{\\sqrt{2 \\pi}}\\int_{-\\gamma}^{\\gamma} \\frac{z}{\\tau} e^{-\\frac{1}{2}\\left( \\frac{z-\\omega}{\\tau} \\right)^2} dz\n",
    "\\end{aligned}\n",
    "\n",
    "Let $u = \\frac{z-\\omega}{\\tau}$, so $z = u \\tau + \\omega$ and $du = \\frac{1}{\\tau}dz$. Substituting these in we get the following:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{1}{\\sqrt{2 \\pi}}\\int_{-\\gamma}^{\\gamma} \\frac{z}{\\tau} e^{-\\frac{1}{2}\\left( \\frac{z-\\omega}{\\tau} \\right)^2} dz\n",
    "&= \\frac{1}{\\sqrt{2 \\pi}} \\left[ \\int (u \\tau + \\omega)e^{-\\frac{1}{2}u^2}du \\right]_{-\\frac{\\gamma + \\omega}{\\tau}}^{\\frac{\\gamma - \\omega}{\\tau}} \\\\\n",
    "&= \\frac{1}{\\sqrt{2 \\pi}} \\left[ \\tau \\int ue^{-\\frac{1}{2}u^2}du + \\omega \\int e^{-\\frac{1}{2}u^2}du \\right]_{-\\frac{\\gamma + \\omega}{\\tau}}^{\\frac{\\gamma - \\omega}{\\tau}} \\\\\n",
    "&= \\frac{1}{\\sqrt{2 \\pi}} \\left[ -\\tau e^{-\\frac{1}{2} u^2} + \\frac{\\omega \\sqrt{\\pi}}{\\sqrt{2}} \\text{erf} \\left( \\frac{u}{\\sqrt{2}} \\right) \\right]_{-\\frac{\\gamma + \\omega}{\\tau}}^{\\frac{\\gamma - \\omega}{\\tau}} \\\\\n",
    "&= \\left[ -\\frac{\\tau}{\\sqrt{2 \\pi}} e^{-\\frac{1}{2}u^2} + \\frac{\\omega}{2} \\text{erf} \\left( \\frac{u}{\\sqrt{2}} \\right) \\right]_{-\\frac{\\gamma + \\omega}{\\tau}}^{\\frac{\\gamma - \\omega}{\\tau}}\n",
    "\\end{aligned}\n",
    "\n",
    "Which evaluated gives:\n",
    "$$\\mathbb{E}Z\\textbf{1}_{\\left| Z \\right| \\le \\gamma} = \\frac{\\omega}{2} \\left[ \\text{erf} \\left( \\frac{\\gamma-\\omega}{\\tau \\sqrt{2}} \\right) - \\text{erf} \\left( \\frac{-(\\gamma+\\omega)}{\\tau \\sqrt{2}} \\right) \\right] - \\frac{\\tau}{\\sqrt{2 \\pi}} \\left[ \\exp\\left\\{-\\frac{1}{2}\\left( \\frac{\\gamma-\\omega}{\\tau} \\right)^2\\right\\} - \\exp\\left\\{-\\frac{1}{2}\\left( \\frac{-(\\gamma+\\omega)}{\\tau} \\right)^2\\right\\} \\right]$$\n",
    "\n",
    "(b)\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}\\left( X - \\hat{\\mu}_n^H \\right)^2 \n",
    "           &= \\mathbb{E}\\left[ (X - \\mu) + (\\mu - \\hat{\\mu}_n^H) \\right]^2 \\\\\n",
    "           &= \\mathbb{E}\\left[ (X - \\mu)^2 + 2(X - \\mu)(\\mu + \\hat{\\mu}_n^H) + (\\mu - \\hat{\\mu}_n^H)^2 \\right] \\\\\n",
    "           &= \\mathbb{E}(X - \\mu)^2 - 2\\mathbb{E}(X - \\mu)(\\mu + \\hat{\\mu}_n^H) + \\mathbb{E}(\\mu - \\hat{\\mu}_n^H)^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}(\\mu - \\hat{\\mu}_n^H)^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}\\left[ (\\mu - \\mathbb{E}\\hat{\\mu}_n^H) + (\\mathbb{E}\\hat{\\mu}_n^H - \\hat{\\mu}_n^H) \\right]^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}(\\mu - \\mathbb{E}\\hat{\\mu}_n^H)^2 + \\mathbb{E}(\\mathbb{E}\\hat{\\mu}_n^H - \\hat{\\mu}_n^H)^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}(\\mu - \\mathbb{E}\\hat{\\mu}_n^H)^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}\\left(\\mu^2 - 2\\mu\\mathbb{E}\\hat{\\mu}_n^H + \\left(\\mathbb{E}\\hat{\\mu}_n^H\\right)^2 \\right) \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}\\mu^2 - 2\\mu\\mathbb{E}\\hat{\\mu}_n^H + \\left(\\mathbb{E}\\hat{\\mu}_n^H\\right)^2 \\\\\n",
    "           &= \\sigma^2 + \\mu^2 - 2\\mu\\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\ge \\alpha} \n",
    "           + \\left(\\mathbb{E}\\bar{X}_n\\textbf{1}_{\\left| \\bar{X}_n \\right| \\ge \\alpha} \\right)^2 \\\\\n",
    "           &= \\sigma^2 + \\mu^2 \n",
    "           - 2\\mu\\left[\\mathbb{E}\\bar{X}_n - \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right] \n",
    "           + \\left[\\mathbb{E}\\bar{X}_n - \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right]^2 \\\\\n",
    "           &= \\sigma^2 + \\mu^2 - 2\\mu^2 + 2\\mu \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha}\n",
    "           + \\left( \\mathbb{E}\\bar{X}_n \\right)^2 - 2\\mathbb{E}\\bar{X}_n \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \n",
    "           + \\left( \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right)^2 \\\\\n",
    "           &= \\sigma^2 - \\mu^2 + 2\\mu \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} + \\mu^2 - 2\\mu \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} + \\left( \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right)^2 \\\\\n",
    "           &= \\sigma^2 + \\left( \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right)^2\n",
    "\\end{aligned}\n",
    "\n",
    "We can plug the closed form from (a) in for $\\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha}$ for a final closed form of $\\mathbb{E}\\left( X - \\hat{\\mu}_n^H \\right)^2$ (not done to save space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-production",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-mississippi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-johnson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-culture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "expanded-scheduling",
   "metadata": {},
   "source": [
    "## 2. (Great British Bake-off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ambient-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoLarsIC, LassoLarsCV, RidgeCV, LinearRegression, Ridge\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-match",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-shaft",
   "metadata": {},
   "source": [
    "First, since $\\epsilon$ and $\\textbf{X}$ are independent we can see that: \n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Var}(Y) &= \\text{Var}(\\textbf{X}^{T}\\beta^{*} + \\epsilon) \\\\\n",
    "&= \\text{Var}(\\textbf{X}^{T}\\beta^{*}) + \\text{Var}(\\epsilon) \\\\\n",
    "&= \\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2 \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Furthmore, we recognize $P(Y - \\textbf{X}^{T}\\beta^{*})^{2} = P\\epsilon^{2}$ as the expected squared residuals.\n",
    "Since $P\\epsilon = 0$ then $P\\epsilon^2 = \\sigma^2$ and $P(Y - \\textbf{X}^{T}\\beta^{*})^{2} = \\sigma^2$.\n",
    "\n",
    "\n",
    "Thus,\n",
    "$$\n",
    "\\begin{align}\n",
    "R^{2} &= 1 - \\frac{P(Y - \\textbf{X}^{T}\\beta^{*})^{2}}{\\text{Var}(Y)} \\\\\n",
    "&= 1 - \\frac{\\sigma^2}{\\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-brush",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-being",
   "metadata": {},
   "source": [
    "Setting $R^2 = .8$ we can solve for $\\sigma^2$ as follows.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    ".8 &= 1 - \\frac{\\sigma^2}{\\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2} \\\\\n",
    ".2 &= \\frac{\\sigma^2}{\\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2} \\\\\n",
    "\\sigma^2 &= .2(\\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2)  \\\\\n",
    ".8\\sigma^2 &= .2(\\beta^{*T}\\Sigma(\\rho)\\beta^{*})  \\\\\n",
    "\\sigma^2 &= .25(\\beta^{*T}\\Sigma(\\rho)\\beta^{*}) \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "guided-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['lasso']*3 + ['adpt lasso']*3 + ['ridge']*3 + ['adpt ridge']*3\n",
    "tunings = ['AIC', 'BIC', 'LOO-CV']*4\n",
    "labs = [labels[i] + ' ' + tunings[i] for i in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "neural-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "emse_table = pd.DataFrame(itertools.product(['sparse', 'dense'], \n",
    "                               labs,\n",
    "                               [10,25,50],\n",
    "                               [0,.25,.5]), \n",
    "             columns=['signal','Method-Tuning', 'p', 'rho'])\n",
    "\n",
    "emse_table['mse'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confused-missile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "      <th>Method-Tuning</th>\n",
       "      <th>p</th>\n",
       "      <th>rho</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sparse</td>\n",
       "      <td>lasso AIC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sparse</td>\n",
       "      <td>lasso AIC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sparse</td>\n",
       "      <td>lasso AIC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sparse</td>\n",
       "      <td>lasso AIC</td>\n",
       "      <td>25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sparse</td>\n",
       "      <td>lasso AIC</td>\n",
       "      <td>25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>dense</td>\n",
       "      <td>adpt ridge LOO-CV</td>\n",
       "      <td>25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>dense</td>\n",
       "      <td>adpt ridge LOO-CV</td>\n",
       "      <td>25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>dense</td>\n",
       "      <td>adpt ridge LOO-CV</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>dense</td>\n",
       "      <td>adpt ridge LOO-CV</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>dense</td>\n",
       "      <td>adpt ridge LOO-CV</td>\n",
       "      <td>50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     signal      Method-Tuning   p   rho   mse\n",
       "0    sparse          lasso AIC  10  0.00  None\n",
       "1    sparse          lasso AIC  10  0.25  None\n",
       "2    sparse          lasso AIC  10  0.50  None\n",
       "3    sparse          lasso AIC  25  0.00  None\n",
       "4    sparse          lasso AIC  25  0.25  None\n",
       "..      ...                ...  ..   ...   ...\n",
       "211   dense  adpt ridge LOO-CV  25  0.25  None\n",
       "212   dense  adpt ridge LOO-CV  25  0.50  None\n",
       "213   dense  adpt ridge LOO-CV  50  0.00  None\n",
       "214   dense  adpt ridge LOO-CV  50  0.25  None\n",
       "215   dense  adpt ridge LOO-CV  50  0.50  None\n",
       "\n",
       "[216 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emse_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "equal-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bic(y_hat, y, D, lamb):\n",
    "    df_l = np.sum(D**2/(D**2 + lamb))\n",
    "    rss = np.sum((y - y_hat)**2)\n",
    "    bic = np.log(rss) + df_l*np.log(len(y))/len(y)\n",
    "    \n",
    "    return bic\n",
    "\n",
    "def calc_aic(y_hat, y, D, lamb):\n",
    "    df_l = np.sum(D**2/(D**2 + lamb))\n",
    "    rss = np.sum((y - y_hat)**2)\n",
    "    aic = np.log(rss) + df_l*2/len(y)\n",
    "    \n",
    "    return aic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "blocked-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_ic(lambs, X, Y, X_star, Y_star, ic='aic'):\n",
    "    U, D, V = np.linalg.svd(X, full_matrices=False)\n",
    "\n",
    "    y_pred = lambda l: (U @ np.diag(D**2/(D**2 + l)) @ U.T) @ Y   \n",
    "    if ic=='bic':\n",
    "        bic_vals = np.array([calc_bic(y_hat = y_pred(l), y=Y, D=D, lamb=l) for l in lambs])\n",
    "        min_i = np.argmin(bic_vals)\n",
    "    else:\n",
    "        aic_vals = np.array([calc_aic(y_hat = y_pred(l), y=Y, D=D, lamb=l) for l in lambs])\n",
    "        min_i = np.argmin(aic_vals)\n",
    "    \n",
    "    p = X.shape[1]\n",
    "    mse = mean_squared_error(Y, y_pred(lambs[min_i]))\n",
    "    \n",
    "    beta_hat = np.linalg.inv(X.T @ X + lambs[min_i]*np.eye(p)) @ X.T @ Y\n",
    "    \n",
    "    omse = mean_squared_error(Y_star, X_star @ beta_hat)\n",
    "    \n",
    "    return mse, lambs[min_i], omse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "civilian-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "p=10\n",
    "rho=.25\n",
    "test_size=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "valid-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_spr = np.fromfunction(lambda j, _: (2 / np.sqrt(n)) * (j + 1 <= np.sqrt(p)), (p, 1))\n",
    "beta_dns = np.fromfunction(lambda j, _: (5 / (j + 1) * np.sqrt(n)), (p, 1))\n",
    "\n",
    "Sigma_p = np.fromfunction(lambda i, j: rho**(np.abs(i - j)), (p, p))\n",
    "sigma2_spr = 0.25 * (beta_spr.T @ Sigma_p @ beta_spr)\n",
    "sigma2_dns = 0.25 * (beta_dns.T @ Sigma_p @ beta_dns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "emotional-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epsilon_spr = np.random.normal(loc=0, scale=np.sqrt(sigma2_spr))\n",
    "test_epsilon_dns = np.random.normal(loc=0, scale=np.sqrt(sigma2_dns))\n",
    "\n",
    "test_X = np.random.multivariate_normal(mean=np.zeros(p), cov=Sigma_p, size=test_size)\n",
    "\n",
    "test_Y_spr =  test_X @ beta_spr + test_epsilon_spr\n",
    "test_Y_dns =  test_X @ beta_dns + test_epsilon_dns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "solid-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "epsilon_spr = np.random.normal(loc=0, scale=np.sqrt(sigma2_spr))\n",
    "epsilon_dns = np.random.normal(loc=0, scale=np.sqrt(sigma2_dns))\n",
    "\n",
    "X = np.random.multivariate_normal(mean=np.zeros(p), cov=Sigma_p, size=n)\n",
    "\n",
    "Y_spr =  X @ beta_spr + epsilon_spr\n",
    "Y_dns =  X @ beta_dns + epsilon_dns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "developing-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, D, V = np.linalg.svd(X, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "robust-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lambda l: (U @ np.diag(D**2/(D**2 + l)) @ U.T) @ Y_dns   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "mighty-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "lams = np.linspace(0,100, num=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "sporting-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xwinter = np.c_[np.ones(n), X]\n",
    "test_X_inter = np.c_[np.ones(test_size), test_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "clinical-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmse, lmin, omse = lambda_ic(lambs=lams, X=Xwinter, Y=Y_dns, X_star=test_X_inter, Y_star=test_Y_dns, ic='bic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "computational-minnesota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316.42846278042725"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "vertical-listing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "stretch-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "complicated-minnesota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316.4284627804267"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(X,Y_dns)\n",
    "mean_squared_error(test_Y_dns, ridge.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "several-kelly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([300.3003003 , 301.3013013 , 302.3023023 , 303.3033033 ,\n",
       "       304.3043043 , 305.30530531, 306.30630631, 307.30730731,\n",
       "       308.30830831, 309.30930931, 310.31031031, 311.31131131,\n",
       "       312.31231231, 313.31331331, 314.31431431, 315.31531532,\n",
       "       316.31631632, 317.31731732, 318.31831832, 319.31931932,\n",
       "       320.32032032, 321.32132132, 322.32232232, 323.32332332,\n",
       "       324.32432432, 325.32532533, 326.32632633, 327.32732733,\n",
       "       328.32832833, 329.32932933, 330.33033033, 331.33133133,\n",
       "       332.33233233, 333.33333333, 334.33433433, 335.33533534,\n",
       "       336.33633634, 337.33733734, 338.33833834, 339.33933934,\n",
       "       340.34034034, 341.34134134, 342.34234234, 343.34334334,\n",
       "       344.34434434, 345.34534535, 346.34634635, 347.34734735,\n",
       "       348.34834835, 349.34934935])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lams[300:350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "regional-batch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:14<20:13,  1.23s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-c64b586b6efa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# Dense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mlasso_bic_dns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLassoLarsIC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mlasso_bic_dns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_dns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mlasso_bic_mse_dns\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_Y_dns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlasso_bic_dns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, copy_X)\u001b[0m\n\u001b[0;32m   1799\u001b[0m         \u001b[0mGram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecompute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1801\u001b[1;33m         alphas_, _, coef_path_, self.n_iter_ = lars_path(\n\u001b[0m\u001b[0;32m   1802\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGram\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_Gram\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1803\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lasso'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py\u001b[0m in \u001b[0;36mlars_path\u001b[1;34m(X, y, Xy, Gram, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[1;34m'Use lars_path_gram to avoid passing X and y.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         )\n\u001b[1;32m--> 155\u001b[1;33m     return _lars_path_solver(\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGram\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0malpha_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py\u001b[0m in \u001b[0;36m_lars_path_solver\u001b[1;34m(X, y, Xy, Gram, n_samples, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[0;32m    555\u001b[0m                                         **SOLVE_TRIANGULAR_ARGS)\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_active\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mn_active\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_active\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mn_active\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m             \u001b[0mdiag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_active\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_active\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n = 100\n",
    "count = 0\n",
    "test_size = 1000\n",
    "for p,rho in itertools.product([10, 25, 50],[0, 0.25, 0.5]):\n",
    "    print(p, rho)\n",
    "    \n",
    "    # Generate data\n",
    "    beta_spr = np.fromfunction(lambda j, _: (2 / np.sqrt(n)) * (j + 1 <= np.sqrt(p)), (p, 1))\n",
    "    beta_dns = np.fromfunction(lambda j, _: (5 / (j + 1) * np.sqrt(n)), (p, 1))\n",
    "\n",
    "    Sigma_p = np.fromfunction(lambda i, j: rho**(np.abs(i - j)), (p, p))\n",
    "    sigma2_spr = 0.25 * (beta_spr.T @ Sigma_p @ beta_spr)\n",
    "    sigma2_dns = 0.25 * (beta_dns.T @ Sigma_p @ beta_dns)\n",
    "    \n",
    "    \n",
    "    #Generate Test sets for given Rho and p\n",
    "    test_epsilon_spr = np.random.normal(loc=0, scale=np.sqrt(sigma2_spr))\n",
    "    test_epsilon_dns = np.random.normal(loc=0, scale=np.sqrt(sigma2_dns))\n",
    "    \n",
    "    test_X = np.random.multivariate_normal(mean=np.zeros(p), cov=Sigma_p, size=test_size)\n",
    "\n",
    "    test_Y_spr =  test_X @ beta_spr + test_epsilon_spr\n",
    "    test_Y_dns =  test_X @ beta_dns + test_epsilon_dns\n",
    "    \n",
    "    # Sparse Signal\n",
    "    lasso_aic_mse_spr = 0\n",
    "    lasso_bic_mse_spr = 0\n",
    "    lasso_loocv_mse_spr = 0\n",
    "    adp_lasso_aic_mse_spr = 0\n",
    "    adp_lasso_bic_mse_spr = 0\n",
    "    adp_lasso_loocv_mse_spr = 0\n",
    "    \n",
    "    ridge_aic_mse_spr = 0\n",
    "    ridge_bic_mse_spr = 0\n",
    "    ridge_loocv_mse_spr = 0\n",
    "    adp_ridge_aic_mse_spr = 0\n",
    "    adp_ridge_bic_mse_spr = 0\n",
    "    adp_ridge_loocv_mse_spr = 0\n",
    "    \n",
    "    # Dense Signal \n",
    "    lasso_aic_mse_dns = 0\n",
    "    lasso_bic_mse_dns = 0\n",
    "    lasso_loocv_mse_dns = 0\n",
    "    adp_lasso_aic_mse_dns = 0\n",
    "    adp_lasso_bic_mse_dns = 0\n",
    "    adp_lasso_loocv_mse_dns = 0\n",
    "    \n",
    "    ridge_aic_mse_dns = 0\n",
    "    ridge_bic_mse_dns = 0\n",
    "    ridge_loocv_mse_dns = 0\n",
    "    adp_ridge_aic_mse_dns = 0\n",
    "    adp_ridge_bic_mse_dns = 0\n",
    "    adp_ridge_loocv_mse_dns = 0\n",
    "    \n",
    "    # For LOO-CV\n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    prog = tqdm(total = 1000, position=0, leave=2)\n",
    "    \n",
    "    for _ in range(1000):\n",
    "        \n",
    "        #To divide out mse sums later\n",
    "        count += 1 \n",
    "        \n",
    "        # Create Dataset\n",
    "        epsilon_spr = np.random.normal(loc=0, scale=np.sqrt(sigma2_spr))\n",
    "        epsilon_dns = np.random.normal(loc=0, scale=np.sqrt(sigma2_dns))\n",
    "\n",
    "        X = np.random.multivariate_normal(mean=np.zeros(p), cov=Sigma_p, size=n)\n",
    "\n",
    "        Y_spr =  X @ beta_spr + epsilon_spr\n",
    "        Y_dns =  X @ beta_dns + epsilon_dns\n",
    "\n",
    "        # For adaptive regressions\n",
    "        lm_spr = LinearRegression().fit(X, Y_spr)\n",
    "        lm_dns = LinearRegression().fit(X, Y_dns)\n",
    "        \n",
    "        # Adpative Lasso\n",
    "        # Here we are compute X^T (D^-1)^T\n",
    "        adX_sprL = X @ np.diagflat(np.abs(lm_spr.coef_))\n",
    "        adX_dnsL = X @ np.diagflat(np.abs(lm_dns.coef_))\n",
    "        \n",
    "        # Adpative Ridge\n",
    "        adX_sprR = X @ np.diagflat((lm_spr.coef_**2)**(1/2))\n",
    "        adX_dnsR = X @ np.diagflat((lm_dns.coef_**2)**(1/2))\n",
    "    \n",
    "        # Calculate Lassos\n",
    "        \n",
    "        # AIC\n",
    "        \n",
    "        # Sparse\n",
    "        lasso_aic_spr = LassoLarsIC(criterion='aic')\n",
    "        lasso_aic_spr.fit(X, Y_spr)\n",
    "        lasso_aic_mse_spr += mean_squared_error(test_Y_spr, lasso_aic_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        lasso_aic_dns = LassoLarsIC(criterion='aic')\n",
    "        lasso_aic_dns.fit(X, Y_dns)\n",
    "        lasso_aic_mse_dns += mean_squared_error(test_Y_dns, lasso_aic_dns.predict(test_X))\n",
    "        \n",
    "        #BIC\n",
    "        \n",
    "        # Sparse\n",
    "        lasso_bic_spr = LassoLarsIC(criterion='bic')\n",
    "        lasso_bic_spr.fit(X, Y_spr)\n",
    "        lasso_bic_mse_spr += mean_squared_error(test_Y_spr, lasso_bic_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        lasso_bic_dns = LassoLarsIC(criterion='bic')\n",
    "        lasso_bic_dns.fit(X, Y_dns)\n",
    "        lasso_bic_mse_dns += mean_squared_error(test_Y_dns, lasso_bic_dns.predict(test_X))\n",
    "        \n",
    "        #LOO-CV\n",
    "        \n",
    "        # Sparse\n",
    "        lasso_loo_spr = LassoLarsCV(cv=loo)\n",
    "        lasso_loo_spr.fit(X, Y_spr)\n",
    "        lasso_loocv_mse_spr += mean_squared_error(test_Y_spr, lasso_loo_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        lasso_loo_dns = LassoLarsCV(cv=loo)\n",
    "        lasso_loo_dns.fit(X, Y_dns)\n",
    "        lasso_loocv_mse_spr += mean_squared_error(test_Y_dns, lasso_loo_dns.predict(test_X))\n",
    "\n",
    "        # Adaptive Lasso\n",
    "        \n",
    "        # AIC\n",
    "        \n",
    "        # Sparse\n",
    "        adp_lasso_aic_spr = LassoLarsIC(criterion='aic')\n",
    "        adp_lasso_aic_spr.fit(adX_sprL, Y_spr)\n",
    "        adp_lasso_aic_mse_spr += mean_squared_error(test_Y_spr, adp_lasso_aic_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        adp_lasso_aic_dns = LassoLarsIC(criterion='aic')\n",
    "        adp_lasso_aic_dns.fit(adX_dnsL, Y_dns)\n",
    "        adp_lasso_aic_mse_dns += mean_squared_error(test_Y_dns, adp_lasso_aic_dns.predict(test_X))\n",
    "        \n",
    "        # BIC\n",
    "        \n",
    "        # Sparse\n",
    "        adp_lasso_bic_spr = LassoLarsIC(criterion='bic')\n",
    "        adp_lasso_bic_spr.fit(adX_sprL, Y_spr)\n",
    "        adp_lasso_bic_mse_spr += mean_squared_error(test_Y_spr, adp_lasso_bic_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        adp_lasso_bic_dns = LassoLarsIC(criterion='bic')\n",
    "        adp_lasso_bic_dns.fit(adX_dnsL, Y_dns)\n",
    "        adp_lasso_bic_mse_dns += mean_squared_error(test_Y_dns, adp_lasso_bic_dns.predict(test_X))\n",
    "        \n",
    "        # LOO-CV\n",
    "        \n",
    "        # Sparse\n",
    "        #adp_lasso_loo_spr = LassoLarsCV(cv=loo)\n",
    "        #adp_lasso_loo_spr.fit(adX_sprL, Y_spr)\n",
    "        #adp_lasso_loocv_mse_spr += mean_squared_error(test_Y_spr, adp_lasso_loo_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        #adp_lasso_loo_dns = LassoLarsCV(cv=loo)\n",
    "        #adp_lasso_loo_dns.fit(adX_dnsL, Y_dns)\n",
    "        #adp_lasso_loocv_mse_dns += mean_squared_error(test_Y_dns, adp_lasso_loo_dns.predict(test_X))\n",
    "\n",
    "        # Calculate Ridge\n",
    "        # AIC\n",
    "\n",
    "        #BIC\n",
    "\n",
    "        #LOO-CV\n",
    "        \n",
    "        #Sparse\n",
    "        ridge_loo_spr = RidgeCV(cv = loo)\n",
    "        ridge_loo_spr.fit(X,Y_spr)\n",
    "        ridge_loocv_mse_spr += mean_squared_error(test_Y_spr, ridge_loo_spr.predict(test_X))\n",
    "        \n",
    "        #Dense\n",
    "        ridge_loo_dns = RidgeCV(cv = loo)\n",
    "        ridge_loo_dns.fit(X,Y_dns)\n",
    "        ridge_loocv_mse_dns += mean_squared_error(test_Y_dns, ridge_loo_dns.predict(test_X))\n",
    "\n",
    "        #Adaptive Ridge\n",
    "        # AIC\n",
    "\n",
    "        # BIC\n",
    "\n",
    "        # LOO-CV\n",
    "        \n",
    "        #Sparse\n",
    "        adp_ridge_loo_spr = RidgeCV(cv = loo)\n",
    "        adp_ridge_loo_spr.fit(adX_sprR,Y_spr)\n",
    "        adp_ridge_loocv_mse_spr += mean_squared_error(test_Y_spr, ridge_loo_spr.predict(test_X))\n",
    "        \n",
    "        #Dense\n",
    "        adp_ridge_loo_dns = RidgeCV(cv = loo)\n",
    "        adp_ridge_loo_dns.fit(adX_dnsR,Y_dns)\n",
    "        adp_ridge_loocv_mse_dns += mean_squared_error(test_Y_dns, ridge_loo_dns.predict(test_X))\n",
    "\n",
    "        \n",
    "        prog.update()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
