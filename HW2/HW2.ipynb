{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3\n",
    "- Author: Marc Brooks\n",
    "- NetID: mgb45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) (Hard-thresholding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(a)\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}Z\\textbf{1}_{\\left| Z \\right| \\le \\gamma}\n",
    "&= \\int_{-\\infty}^{\\infty} \\frac{z}{\\tau \\sqrt{2 \\pi}} e^{-\\frac{1}{2}\\left( \\frac{z-\\omega}{\\tau} \\right)^2}\\textbf{1}_{\\left| Z \\right| \\le \\gamma} dz \\\\\n",
    "&= \\frac{1}{\\sqrt{2 \\pi}}\\int_{-\\gamma}^{\\gamma} \\frac{z}{\\tau} e^{-\\frac{1}{2}\\left( \\frac{z-\\omega}{\\tau} \\right)^2} dz\n",
    "\\end{aligned}\n",
    "\n",
    "Let $u = \\frac{z-\\omega}{\\tau}$, so $z = u \\tau + \\omega$ and $du = \\frac{1}{\\tau}dz$. Substituting these in we get the following:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{1}{\\sqrt{2 \\pi}}\\int_{-\\gamma}^{\\gamma} \\frac{z}{\\tau} e^{-\\frac{1}{2}\\left( \\frac{z-\\omega}{\\tau} \\right)^2} dz\n",
    "&= \\frac{1}{\\sqrt{2 \\pi}} \\left[ \\int (u \\tau + \\omega)e^{-\\frac{1}{2}u^2}du \\right]_{-\\frac{\\gamma + \\omega}{\\tau}}^{\\frac{\\gamma - \\omega}{\\tau}} \\\\\n",
    "&= \\frac{1}{\\sqrt{2 \\pi}} \\left[ \\tau \\int ue^{-\\frac{1}{2}u^2}du + \\omega \\int e^{-\\frac{1}{2}u^2}du \\right]_{-\\frac{\\gamma + \\omega}{\\tau}}^{\\frac{\\gamma - \\omega}{\\tau}} \\\\\n",
    "&= \\frac{1}{\\sqrt{2 \\pi}} \\left[ -\\tau e^{-\\frac{1}{2} u^2} + \\frac{\\omega \\sqrt{\\pi}}{\\sqrt{2}} \\text{erf} \\left( \\frac{u}{\\sqrt{2}} \\right) \\right]_{-\\frac{\\gamma + \\omega}{\\tau}}^{\\frac{\\gamma - \\omega}{\\tau}} \\\\\n",
    "&= \\left[ -\\frac{\\tau}{\\sqrt{2 \\pi}} e^{-\\frac{1}{2}u^2} + \\frac{\\omega}{2} \\text{erf} \\left( \\frac{u}{\\sqrt{2}} \\right) \\right]_{-\\frac{\\gamma + \\omega}{\\tau}}^{\\frac{\\gamma - \\omega}{\\tau}}\n",
    "\\end{aligned}\n",
    "\n",
    "Which evaluated gives:\n",
    "$$\\mathbb{E}Z\\textbf{1}_{\\left| Z \\right| \\le \\gamma} = \\frac{\\omega}{2} \\left[ \\text{erf} \\left( \\frac{\\gamma-\\omega}{\\tau \\sqrt{2}} \\right) - \\text{erf} \\left( \\frac{-(\\gamma+\\omega)}{\\tau \\sqrt{2}} \\right) \\right] - \\frac{\\tau}{\\sqrt{2 \\pi}} \\left[ \\exp\\left\\{-\\frac{1}{2}\\left( \\frac{\\gamma-\\omega}{\\tau} \\right)^2\\right\\} - \\exp\\left\\{-\\frac{1}{2}\\left( \\frac{-(\\gamma+\\omega)}{\\tau} \\right)^2\\right\\} \\right]$$\n",
    "\n",
    "(b)\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}\\left( X - \\hat{\\mu}_n^H \\right)^2 \n",
    "           &= \\mathbb{E}\\left[ (X - \\mu) + (\\mu - \\hat{\\mu}_n^H) \\right]^2 \\\\\n",
    "           &= \\mathbb{E}\\left[ (X - \\mu)^2 + 2(X - \\mu)(\\mu + \\hat{\\mu}_n^H) + (\\mu - \\hat{\\mu}_n^H)^2 \\right] \\\\\n",
    "           &= \\mathbb{E}(X - \\mu)^2 - 2\\mathbb{E}(X - \\mu)(\\mu + \\hat{\\mu}_n^H) + \\mathbb{E}(\\mu - \\hat{\\mu}_n^H)^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}(\\mu - \\hat{\\mu}_n^H)^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}\\left[ (\\mu - \\mathbb{E}\\hat{\\mu}_n^H) + (\\mathbb{E}\\hat{\\mu}_n^H - \\hat{\\mu}_n^H) \\right]^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}(\\mu - \\mathbb{E}\\hat{\\mu}_n^H)^2 + \\mathbb{E}(\\mathbb{E}\\hat{\\mu}_n^H - \\hat{\\mu}_n^H)^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}(\\mu - \\mathbb{E}\\hat{\\mu}_n^H)^2 \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}\\left(\\mu^2 - 2\\mu\\mathbb{E}\\hat{\\mu}_n^H + \\left(\\mathbb{E}\\hat{\\mu}_n^H\\right)^2 \\right) \\\\\n",
    "           &= \\sigma^2 + \\mathbb{E}\\mu^2 - 2\\mu\\mathbb{E}\\hat{\\mu}_n^H + \\left(\\mathbb{E}\\hat{\\mu}_n^H\\right)^2 \\\\\n",
    "           &= \\sigma^2 + \\mu^2 - 2\\mu\\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\ge \\alpha} \n",
    "           + \\left(\\mathbb{E}\\bar{X}_n\\textbf{1}_{\\left| \\bar{X}_n \\right| \\ge \\alpha} \\right)^2 \\\\\n",
    "           &= \\sigma^2 + \\mu^2 \n",
    "           - 2\\mu\\left[\\mathbb{E}\\bar{X}_n - \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right] \n",
    "           + \\left[\\mathbb{E}\\bar{X}_n - \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right]^2 \\\\\n",
    "           &= \\sigma^2 + \\mu^2 - 2\\mu^2 + 2\\mu \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha}\n",
    "           + \\left( \\mathbb{E}\\bar{X}_n \\right)^2 - 2\\mathbb{E}\\bar{X}_n \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \n",
    "           + \\left( \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right)^2 \\\\\n",
    "           &= \\sigma^2 - \\mu^2 + 2\\mu \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} + \\mu^2 - 2\\mu \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} + \\left( \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right)^2 \\\\\n",
    "           &= \\sigma^2 + \\left( \\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha} \\right)^2\n",
    "\\end{aligned}\n",
    "\n",
    "We can plug the closed form from (a) in for $\\mathbb{E}\\bar{X}_n \\textbf{1}_{\\left| \\bar{X}_n \\right| \\le \\alpha}$ for a final closed form of $\\mathbb{E}\\left( X - \\hat{\\mu}_n^H \\right)^2$ (not done to save space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (Great British Bake-off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoLarsIC, LassoLarsCV, RidgeCV, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, since $\\epsilon$ and $\\textbf{X}$ are independent we can see that: \n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Var}(Y) &= \\text{Var}(\\textbf{X}^{T}\\beta^{*} + \\epsilon) \\\\\n",
    "&= \\text{Var}(\\textbf{X}^{T}\\beta^{*}) + \\text{Var}(\\epsilon) \\\\\n",
    "&= \\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2 \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Furthmore, we recognize $P(Y - \\textbf{X}^{T}\\beta^{*})^{2} = P\\epsilon^{2}$ as the expected squared residuals.\n",
    "Since $P\\epsilon = 0$ then $P\\epsilon^2 = \\sigma^2$ and $P(Y - \\textbf{X}^{T}\\beta^{*})^{2} = \\sigma^2$.\n",
    "\n",
    "\n",
    "Thus,\n",
    "$$\n",
    "\\begin{align}\n",
    "R^{2} &= 1 - \\frac{P(Y - \\textbf{X}^{T}\\beta^{*})^{2}}{\\text{Var}(Y)} \\\\\n",
    "&= 1 - \\frac{\\sigma^2}{\\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting $R^2 = .8$ we can solve for $\\sigma^2$ as follows.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    ".8 &= 1 - \\frac{\\sigma^2}{\\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2} \\\\\n",
    ".2 &= \\frac{\\sigma^2}{\\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2} \\\\\n",
    "\\sigma^2 &= .2(\\beta^{*T}\\Sigma(\\rho)\\beta^{*} + \\sigma^2)  \\\\\n",
    ".8\\sigma^2 &= .2(\\beta^{*T}\\Sigma(\\rho)\\beta^{*})  \\\\\n",
    "\\sigma^2 &= .25(\\beta^{*T}\\Sigma(\\rho)\\beta^{*}) \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = [10, 25, 50]\n",
    "rho = [0, .25, .5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating data sets with sparse signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X @ np.diagflat(np.abs(lm_spr.coef_))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['lasso']*3 + ['adpt lasso']*3 + ['ridge']*3 + ['adpt ridge']*3\n",
    "tunings = ['AIC', 'BIC', 'LOO-CV']*4\n",
    "labs = [labels[i] + ' ' + tunings[i] for i in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-75-a25a3e8cb16f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-75-a25a3e8cb16f>\"\u001B[1;36m, line \u001B[1;32m2\u001B[0m\n\u001B[1;33m    None                 labs,\u001B[0m\n\u001B[1;37m                         ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "emse_table = pd.DataFrame(itertools.product(['sparse', 'dense'], \n",
    "              None                 labs,\n",
    "                               [10,25,50],\n",
    "                               [0,.25,.5]), \n",
    "             columns=['signal','Method-Tuning', 'p', 'rho'])\n",
    "\n",
    "emse_table['mse'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emse_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-76-6e9ef517607d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0memse_table\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'emse_table' is not defined"
     ]
    }
   ],
   "source": [
    "emse_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, D, V = np.linalg.svd(X, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(D**2/(D**2 + .02)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_output = (U@ np.diag(D**2/(D**2 + .02)) @ U.T) @ Y_spr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_bic(lambs, design_mat, Y_mat):\n",
    "    U, D, V = np.linalg.svd(design_mat, full_matrices=False)\n",
    "    \n",
    "    max_i = np.argmax([mean_squared_error(Y_mat, (U @ np.diag(D**2/(D**2 + l)) @ U.T) @ Y_mat) for l in lambs])\n",
    "    return lambds[max_i]\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-81-9d41f4e4fdfc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mlambda_bic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinspace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY_spr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mlinspace\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32mc:\\users\\jwmcc\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\function_base.py\u001B[0m in \u001B[0;36mlinspace\u001B[1;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m     \"\"\"\n\u001B[1;32m--> 113\u001B[1;33m     \u001B[0mnum\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moperator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    114\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mnum\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Number of samples, %s, must be non-negative.\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mnum\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "lambda_bic(np.linspace(0,1,.01), X, Y_spr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "? np.linalg.svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:14<20:13,  1.23s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-79-c64b586b6efa>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    110\u001B[0m         \u001B[1;31m# Dense\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m         \u001B[0mlasso_bic_dns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mLassoLarsIC\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcriterion\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'bic'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 112\u001B[1;33m         \u001B[0mlasso_bic_dns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY_dns\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    113\u001B[0m         \u001B[0mlasso_bic_mse_dns\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mmean_squared_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_Y_dns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlasso_bic_dns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_X\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, copy_X)\u001B[0m\n\u001B[0;32m   1799\u001B[0m         \u001B[0mGram\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprecompute\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1800\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1801\u001B[1;33m         alphas_, _, coef_path_, self.n_iter_ = lars_path(\n\u001B[0m\u001B[0;32m   1802\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mGram\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mGram\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy_X\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy_X\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy_Gram\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha_min\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1803\u001B[0m             \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'lasso'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_iter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmax_iter\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     70\u001B[0m                           FutureWarning)\n\u001B[0;32m     71\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     73\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py\u001B[0m in \u001B[0;36mlars_path\u001B[1;34m(X, y, Xy, Gram, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001B[0m\n\u001B[0;32m    153\u001B[0m             \u001B[1;34m'Use lars_path_gram to avoid passing X and y.'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    154\u001B[0m         )\n\u001B[1;32m--> 155\u001B[1;33m     return _lars_path_solver(\n\u001B[0m\u001B[0;32m    156\u001B[0m         \u001B[0mX\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mXy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mXy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mGram\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mGram\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_samples\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_iter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmax_iter\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    157\u001B[0m         \u001B[0malpha_min\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0malpha_min\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy_X\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy_X\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py\u001B[0m in \u001B[0;36m_lars_path_solver\u001B[1;34m(X, y, Xy, Gram, n_samples, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001B[0m\n\u001B[0;32m    555\u001B[0m                                         **SOLVE_TRIANGULAR_ARGS)\n\u001B[0;32m    556\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 557\u001B[1;33m             \u001B[0mv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mL\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mn_active\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[0mn_active\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mL\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mn_active\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[0mn_active\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    558\u001B[0m             \u001B[0mdiag\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mabs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mc\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    559\u001B[0m             \u001B[0mL\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mn_active\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_active\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdiag\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mdot\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n = 100\n",
    "count = 0\n",
    "test_size = 1000\n",
    "for p,rho in itertools.product([10, 25, 50],[0, 0.25, 0.5]):\n",
    "    print(p, rho)\n",
    "    \n",
    "    # Generate data\n",
    "    beta_spr = np.fromfunction(lambda j, _: (2 / np.sqrt(n)) * (j + 1 <= np.sqrt(p)), (p, 1))\n",
    "    beta_dns = np.fromfunction(lambda j, _: (5 / (j + 1) * np.sqrt(n)), (p, 1))\n",
    "\n",
    "    Sigma_p = np.fromfunction(lambda i, j: rho**(np.abs(i - j)), (p, p))\n",
    "    sigma2_spr = 0.25 * (beta_spr.T @ Sigma_p @ beta_spr)\n",
    "    sigma2_dns = 0.25 * (beta_dns.T @ Sigma_p @ beta_dns)\n",
    "    \n",
    "    \n",
    "    #Generate Test sets for given Rho and p\n",
    "    test_epsilon_spr = np.random.normal(loc=0, scale=np.sqrt(sigma2_spr))\n",
    "    test_epsilon_dns = np.random.normal(loc=0, scale=np.sqrt(sigma2_dns))\n",
    "    \n",
    "    test_X = np.random.multivariate_normal(mean=np.zeros(p), cov=Sigma_p, size=test_size)\n",
    "\n",
    "    test_Y_spr =  test_X @ beta_spr + test_epsilon_spr\n",
    "    test_Y_dns =  test_X @ beta_dns + test_epsilon_dns\n",
    "    \n",
    "    # Sparse Signal\n",
    "    lasso_aic_mse_spr = 0\n",
    "    lasso_bic_mse_spr = 0\n",
    "    lasso_loocv_mse_spr = 0\n",
    "    adp_lasso_aic_mse_spr = 0\n",
    "    adp_lasso_bic_mse_spr = 0\n",
    "    adp_lasso_loocv_mse_spr = 0\n",
    "    \n",
    "    ridge_aic_mse_spr = 0\n",
    "    ridge_bic_mse_spr = 0\n",
    "    ridge_loocv_mse_spr = 0\n",
    "    adp_ridge_aic_mse_spr = 0\n",
    "    adp_ridge_bic_mse_spr = 0\n",
    "    adp_ridge_loocv_mse_spr = 0\n",
    "    \n",
    "    # Dense Signal \n",
    "    lasso_aic_mse_dns = 0\n",
    "    lasso_bic_mse_dns = 0\n",
    "    lasso_loocv_mse_dns = 0\n",
    "    adp_lasso_aic_mse_dns = 0\n",
    "    adp_lasso_bic_mse_dns = 0\n",
    "    adp_lasso_loocv_mse_dns = 0\n",
    "    \n",
    "    ridge_aic_mse_dns = 0\n",
    "    ridge_bic_mse_dns = 0\n",
    "    ridge_loocv_mse_dns = 0\n",
    "    adp_ridge_aic_mse_dns = 0\n",
    "    adp_ridge_bic_mse_dns = 0\n",
    "    adp_ridge_loocv_mse_dns = 0\n",
    "    \n",
    "    # For LOO-CV\n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    prog = tqdm(total = 1000, position=0, leave=2)\n",
    "    \n",
    "    for _ in range(1000):\n",
    "        \n",
    "        #To divide out mse sums later\n",
    "        count += 1 \n",
    "        \n",
    "        # Create Dataset\n",
    "        epsilon_spr = np.random.normal(loc=0, scale=np.sqrt(sigma2_spr))\n",
    "        epsilon_dns = np.random.normal(loc=0, scale=np.sqrt(sigma2_dns))\n",
    "\n",
    "        X = np.random.multivariate_normal(mean=np.zeros(p), cov=Sigma_p, size=n)\n",
    "\n",
    "        Y_spr =  X @ beta_spr + epsilon_spr\n",
    "        Y_dns =  X @ beta_dns + epsilon_dns\n",
    "\n",
    "        # For adaptive regressions\n",
    "        lm_spr = LinearRegression().fit(X, Y_spr)\n",
    "        lm_dns = LinearRegression().fit(X, Y_dns)\n",
    "        \n",
    "        # Adpative Lasso\n",
    "        # Here we are compute X^T (D^-1)^T\n",
    "        adX_sprL = X @ np.diagflat(np.abs(lm_spr.coef_))\n",
    "        adX_dnsL = X @ np.diagflat(np.abs(lm_dns.coef_))\n",
    "        \n",
    "        # Adpative Ridge\n",
    "        adX_sprR = X @ np.diagflat((lm_spr.coef_**2)**(1/2))\n",
    "        adX_dnsR = X @ np.diagflat((lm_dns.coef_**2)**(1/2))\n",
    "    \n",
    "        # Calculate Lassos\n",
    "        \n",
    "        # AIC\n",
    "        \n",
    "        # Sparse\n",
    "        lasso_aic_spr = LassoLarsIC(criterion='aic')\n",
    "        lasso_aic_spr.fit(X, Y_spr)\n",
    "        lasso_aic_mse_spr += mean_squared_error(test_Y_spr, lasso_aic_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        lasso_aic_dns = LassoLarsIC(criterion='aic')\n",
    "        lasso_aic_dns.fit(X, Y_dns)\n",
    "        lasso_aic_mse_dns += mean_squared_error(test_Y_dns, lasso_aic_dns.predict(test_X))\n",
    "        \n",
    "        #BIC\n",
    "        \n",
    "        # Sparse\n",
    "        lasso_bic_spr = LassoLarsIC(criterion='bic')\n",
    "        lasso_bic_spr.fit(X, Y_spr)\n",
    "        lasso_bic_mse_spr += mean_squared_error(test_Y_spr, lasso_bic_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        lasso_bic_dns = LassoLarsIC(criterion='bic')\n",
    "        lasso_bic_dns.fit(X, Y_dns)\n",
    "        lasso_bic_mse_dns += mean_squared_error(test_Y_dns, lasso_bic_dns.predict(test_X))\n",
    "        \n",
    "        #LOO-CV\n",
    "        \n",
    "        # Sparse\n",
    "        lasso_loo_spr = LassoLarsCV(cv=loo)\n",
    "        lasso_loo_spr.fit(X, Y_spr)\n",
    "        lasso_loocv_mse_spr += mean_squared_error(test_Y_spr, lasso_loo_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        lasso_loo_dns = LassoLarsCV(cv=loo)\n",
    "        lasso_loo_dns.fit(X, Y_dns)\n",
    "        lasso_loocv_mse_spr += mean_squared_error(test_Y_dns, lasso_loo_dns.predict(test_X))\n",
    "\n",
    "        # Adaptive Lasso\n",
    "        \n",
    "        # AIC\n",
    "        \n",
    "        # Sparse\n",
    "        adp_lasso_aic_spr = LassoLarsIC(criterion='aic')\n",
    "        adp_lasso_aic_spr.fit(adX_sprL, Y_spr)\n",
    "        adp_lasso_aic_mse_spr += mean_squared_error(test_Y_spr, adp_lasso_aic_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        adp_lasso_aic_dns = LassoLarsIC(criterion='aic')\n",
    "        adp_lasso_aic_dns.fit(adX_dnsL, Y_dns)\n",
    "        adp_lasso_aic_mse_dns += mean_squared_error(test_Y_dns, adp_lasso_aic_dns.predict(test_X))\n",
    "        \n",
    "        # BIC\n",
    "        \n",
    "        # Sparse\n",
    "        adp_lasso_bic_spr = LassoLarsIC(criterion='bic')\n",
    "        adp_lasso_bic_spr.fit(adX_sprL, Y_spr)\n",
    "        adp_lasso_bic_mse_spr += mean_squared_error(test_Y_spr, adp_lasso_bic_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        adp_lasso_bic_dns = LassoLarsIC(criterion='bic')\n",
    "        adp_lasso_bic_dns.fit(adX_dnsL, Y_dns)\n",
    "        adp_lasso_bic_mse_dns += mean_squared_error(test_Y_dns, adp_lasso_bic_dns.predict(test_X))\n",
    "        \n",
    "        # LOO-CV\n",
    "        \n",
    "        # Sparse\n",
    "        #adp_lasso_loo_spr = LassoLarsCV(cv=loo)\n",
    "        #adp_lasso_loo_spr.fit(adX_sprL, Y_spr)\n",
    "        #adp_lasso_loocv_mse_spr += mean_squared_error(test_Y_spr, adp_lasso_loo_spr.predict(test_X))\n",
    "        \n",
    "        # Dense\n",
    "        #adp_lasso_loo_dns = LassoLarsCV(cv=loo)\n",
    "        #adp_lasso_loo_dns.fit(adX_dnsL, Y_dns)\n",
    "        #adp_lasso_loocv_mse_dns += mean_squared_error(test_Y_dns, adp_lasso_loo_dns.predict(test_X))\n",
    "\n",
    "        # Calculate Ridge\n",
    "        # AIC\n",
    "\n",
    "        #BIC\n",
    "\n",
    "        #LOO-CV\n",
    "        \n",
    "        #Sparse\n",
    "        ridge_loo_spr = RidgeCV(cv = loo)\n",
    "        ridge_loo_spr.fit(X,Y_spr)\n",
    "        ridge_loocv_mse_spr += mean_squared_error(test_Y_spr, ridge_loo_spr.predict(test_X))\n",
    "        \n",
    "        #Dense\n",
    "        ridge_loo_dns = RidgeCV(cv = loo)\n",
    "        ridge_loo_dns.fit(X,Y_dns)\n",
    "        ridge_loocv_mse_dns += mean_squared_error(test_Y_dns, ridge_loo_dns.predict(test_X))\n",
    "\n",
    "        #Adaptive Ridge\n",
    "        # AIC\n",
    "\n",
    "        # BIC\n",
    "\n",
    "        # LOO-CV\n",
    "        \n",
    "        #Sparse\n",
    "        adp_ridge_loo_spr = RidgeCV(cv = loo)\n",
    "        adp_ridge_loo_spr.fit(adX_sprR,Y_spr)\n",
    "        adp_ridge_loocv_mse_spr += mean_squared_error(test_Y_spr, ridge_loo_spr.predict(test_X))\n",
    "        \n",
    "        #Dense\n",
    "        adp_ridge_loo_dns = RidgeCV(cv = loo)\n",
    "        adp_ridge_loo_dns.fit(adX_dnsR,Y_dns)\n",
    "        adp_ridge_loocv_mse_dns += mean_squared_error(test_Y_dns, ridge_loo_dns.predict(test_X))\n",
    "\n",
    "        \n",
    "        prog.update()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}