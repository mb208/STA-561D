{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull, Delaunay\n",
    "from scipy.stats import dirichlet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import det\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRFRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ConvexHull(X):\n",
    "    \"\"\"Returns points that form convex hull of X\"\"\"\n",
    "    \n",
    "    hull = ConvexHull(X)\n",
    "    \n",
    "    return X[hull.vertices, :]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleConvexHull(X):\n",
    "    \"\"\"Returns sample from convex hull by taking convex combination points X\n",
    "    Input:\n",
    "        X ~ vertices of convex hull (hypothetically)\n",
    "        \n",
    "    Ouput:\n",
    "        x_hat : convex combination of uniformly sampled weights\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    d = X.shape[0]\n",
    "    wghts = np.random.rand(d)\n",
    "    wghts /= wghts.sum()\n",
    "    \n",
    "    return wghts.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernelRFdist(X, xstar, rf):\n",
    "    \"\"\"For new data point get kernel distance with each training data point from a random forrest\"\"\"\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    kernel_rf = np.zeros(n)\n",
    "    for tree in rf.estimators_:\n",
    "        \n",
    "        leaves_tr = tree.apply(X)\n",
    "        leaf_str = tree.apply(xstar.reshape(1, -1))\n",
    "        kernel = 1*(leaf_str == leaves_tr[None,:])\n",
    "        kernel_rf = kernel_rf + kernel\n",
    "        \n",
    "    return kernel_rf/rf.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boostrap_subset(X, M, size=1000):\n",
    "    \"\"\"Returns boostrap of X with subset of columns of size M\"\"\"\n",
    "    \n",
    "    n, p = X.shape\n",
    "    b_ids = np.random.choice(np.arange(n), size=size)\n",
    "    \n",
    "    p_ids = np.random.choice(np.arange(p), size=M, replace=False)\n",
    "    \n",
    "    return X[b_ids, p_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barf(X, y, mod, use_hull = False, B=1000, ntrees=100):\n",
    "    \"\"\"Takes blackbox model fits f(Z) to Zs sampled from convex hull of X and returns a random forrest fitted to\n",
    "       Zs and f(z)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fit blackblox estimator \n",
    "    mod.fit(X,y)\n",
    "    \n",
    "    # Sample X from convex hull\n",
    "    if use_hull:x\n",
    "        if X.shape[1] > 7:\n",
    "            X = X[:, np.random.choice(np.arange(X.shape[1]), replace=False, size=7)].copy()\n",
    "        \n",
    "        \n",
    "        hull = get_ConvexHull(X)\n",
    "        Z = np.r_[[sampleConvexHull(hull) for b in range(B)]]\n",
    "        \n",
    "    else:\n",
    "        Z = np.r_[[sampleConvexHull(X) for b in range(B)]]\n",
    "        \n",
    "    \n",
    "    # Get predictions from convex hull\n",
    "    fhat = mod.predict(Z)\n",
    "    \n",
    "    # fit random forrest,\n",
    "    rf = RandomForestRegressor(n_estimators=ntrees)\n",
    "    rf.fit(Z, fhat)\n",
    "    \n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_linear(X,y, xstar, kern):\n",
    "    \"\"\"Fits local linear model with kernl\"\"\"\n",
    "    \n",
    "    n,p = X.shape\n",
    "    beta = np.zeros(p)\n",
    "    gamma_n = np.zeros((p,p))\n",
    "    sigma_n = np.zeros(p)\n",
    "    for i in range(n):\n",
    "        gamma_n = gamma_n + (X[i,:][:,None] @ X[i,:][None,:] )* kern[i]\n",
    "        sigma_n = sigma_n +  X[i, :]*y[i] * kern[i]\n",
    "    \n",
    "    beta = np.linalg.inv(gamma_n) @ sigma_n\n",
    "    \n",
    "    return xstar.dot(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barfKernel_reg(X, y, Xstar,  mod, use_hull = False, B=1000, ntrees=100):\n",
    "    \"\"\"Fits local linear model using bourne again regression tree kernel\"\"\"\n",
    "    \n",
    "    \n",
    "    rf = barf(X, y, mod, use_hull, B, ntrees)\n",
    "    preds=[]\n",
    "    for i, xstar in enumerate(Xstar):\n",
    "        kern_i = kernelRFdist(X, xstar, rf)\n",
    "        preds.append(local_linear(X=X, y=y, xstar=xstar, kern=kern_i.ravel()))\n",
    "        \n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes[\"data\"]\n",
    "y = diabetes[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:380]\n",
    "y_train = y[:380]\n",
    "X_test  = X[380:]\n",
    "y_test  = y[380:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modRF = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modRF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "modXGB = XGBRFRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsRF = barfKernel_reg(X=X_train, y=y_train, Xstar=X_test, mod=modRF)\n",
    "predsXGB = barfKernel_reg(X=X_train, y=y_train, Xstar=X_test, mod=modXGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5892.641411573515"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, predsRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3117.4206719490444"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, predsXGB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
